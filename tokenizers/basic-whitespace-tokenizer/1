import timeit
from memory_profiler import profile

def tokenize(input_text):
	# basically input_text.lower().split()
	tokens = []
	curr_token = []
	lower_input_text = input_text.lower()
	for char in lower_input_text:
		if char.isspace():
			if curr_token:
				tokens.append("".join(curr_token))
				curr_token = []
		else:
			curr_token.append(char)
	if curr_token:
		tokens.append("".join(curr_token))
	return tokens

@profile
def profile_tokenizer():
	sample = ("hELlo " * 1000 + "\t" * 100 + "test " * 500) * 100
	tokenize(sample)

if __name__ == "__main__":
	print("Time taken:", timeit.timeit(profile_tokenizer, number=10))
